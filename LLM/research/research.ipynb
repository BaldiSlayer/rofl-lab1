{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p9cJFLdEfS1"
   },
   "source": [
    "### Гипотезы\n",
    "1. Убрать ненужные слова по типу: расскажи, докажи, из, ...\n",
    "\n",
    "    Есть два пути: выбрать опорные слова из определений и оставить только их или собрать служебные и второстепенные слова и выкинуть служебные\n",
    "2. На каком языке лучше английском или русском? (кажется, что модель вообще не воспринимает русский и проще дообучить). Что лучше: улучшить перевод или дообучить модель?\n",
    "3. Дообучить модель на корпусте текста (учебник мб)\n",
    "4. Взять другую, русскую модель и использовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDA-IlpYI4vM"
   },
   "source": [
    "### Как считаю метрику?\n",
    "Беру два вопроса: пользовательский и из базы знаний, привожу их к одному виду (прописные буквы, начальная форма, удаление стоп слов), потом считаю пересечение и делю на количество слов в вопросе из БЗ.\n",
    "\n",
    "**Улчушение**: для каждого слова определить его важность: как количество вхождений в БЗ, либо ручками составить словарь с важными терминами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "glT_rP-9pK0q",
    "outputId": "00326484-75c8-4536-aa96-73a3a2f85f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=717f72e37f547eba124c6d4861e622e7341d547df8737bad7e90b148384f6624\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PMtjmNHRSAE3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fa2StkXMo6Ko",
    "outputId": "33603799-ae45-4f98-c2ad-b6afe1cfe529"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "stopwords_ru = stopwords.words('russian')\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "TugFS0eVp417"
   },
   "outputs": [],
   "source": [
    "def make_beautiful(text):\n",
    "    text = text.lower() # единый формат\n",
    "    text = re.sub('\\n|\\t|\\r', ' ', text) # убираем лишнее\n",
    "    sents = sent_tokenize(text) # разбиваем на предложения\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    sents_tokenize = [tokenizer.tokenize(item) for item in sents] # разбиваем на слова\n",
    "    sents_tokenize = [[item for item in sent if item not in stopwords_ru] for sent in sents_tokenize] # лемматизируйте все слова из датасета\n",
    "    sents_tokenize = [[morph.normal_forms(item)[0] for item in sent] for sent in sents_tokenize] # лемматизируйте все слова из датасета\n",
    "    words = [item for sent in sents_tokenize for item in sent] # получаем обработанные слова\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1hYwHpE5q6Dt"
   },
   "outputs": [],
   "source": [
    "def calculate_k(user, database):\n",
    "    in_both = list(set(user) & set(database))\n",
    "    k = len(in_both) / len(database)\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "bt5_a_G4dt6O"
   },
   "outputs": [],
   "source": [
    "question = make_beautiful('Как можно вычислить частичные производные Антимирова?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jW752ahHdmU0"
   },
   "outputs": [],
   "source": [
    "user_question = make_beautiful('че такое эти ваши производные антимирова')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fGNiUj7KrcNf"
   },
   "outputs": [],
   "source": [
    "K = calculate_k(user_question, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OcicfL0rjWO",
    "outputId": "edd7153d-e840-42c9-cdf4-2ceeed729bf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "tNm6wd71ITCU"
   },
   "outputs": [],
   "source": [
    "word_dict = Counter(question)\n",
    "word_dict.most_common()[:20]\n",
    "words = word_dict.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuI4Reh2WkCo",
    "outputId": "732bf5b4-bcde-4a1e-ab64-509a4f96f451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('вычислить', 1), ('частичный', 1), ('производный', 1), ('антимиров', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CYBllffWWuAz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
